{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:02.658384Z",
     "start_time": "2024-04-18T13:16:58.094390Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, T5ForConditionalGeneration\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.246414Z",
     "start_time": "2024-04-18T13:17:02.658384Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.278409Z",
     "start_time": "2024-04-18T13:17:03.246414Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '../../data/tsv/train.tsv'\n",
    "test_path = '../../data/tsv/test.tsv'\n",
    "\n",
    "from data.dataset import TextGraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep and finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:06.272205Z",
     "start_time": "2024-04-18T13:17:03.282394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_bert = AutoModel.from_pretrained(model_name,)\n",
    "\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# model_name = \"whaleloops/phrase-bert\"\n",
    "# model_name = \"DeepPavlov/t5-wikidata5M-with-neighbors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.072235Z",
     "start_time": "2024-04-18T13:17:06.272205Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_bert):\n",
    "        super().__init__()\n",
    "        self.bert_backbone = pretrained_bert\n",
    "        self.hidden_size = pretrained_bert.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_size // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert_backbone(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state  # Access the last hidden states\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the [CLS] token representation\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "model = QuestionClassifier(\n",
    "    pretrained_bert\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.088222Z",
     "start_time": "2024-04-18T13:17:07.072235Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.292235Z",
     "start_time": "2024-04-18T13:17:07.088222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589824 || all params: 110371969 || trainable%: 0.5343965549803682\n",
      "Unfreezing head\n",
      "trainable params: 885505 || all params: 110371969 || trainable%: 0.8022915673453284\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, LoraModel, get_peft_model\n",
    "\n",
    "LORA_RANK=16 # 16 default\n",
    "LORA_ALPHA=32.\n",
    "LORA_DROPOUT=1e-1\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=LORA_RANK,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    # target_modules=[\"query\", \"value\"], # for minilm\n",
    "    target_modules=[\"q\", \"v\"], # for MPNet\n",
    "    # target_modules=[\"q\", \"v\"], # T5 [\"q\", \"v\", \"k\", \"o\"]\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    use_rslora=True,\n",
    ")\n",
    "\n",
    "lora_model = LoraModel(model, config, \"default\")\n",
    "##  make sure to first wrap the base model by calling get_peft_model before wrapping it in PyTorch\n",
    "# lora_model = get_peft_model(model, config)\n",
    "\n",
    "print_trainable_parameters(lora_model)\n",
    "\n",
    "print('Unfreezing head')\n",
    "# Unfreeze the clf head\n",
    "for p in lora_model.head.parameters():\n",
    "    p.requires_grad = True\n",
    "print_trainable_parameters(lora_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the parameters are frozen\n",
    "\n",
    "# for n, p in lora_model.named_parameters():\n",
    "#     print(p.requires_grad, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.356224Z",
     "start_time": "2024-04-18T13:17:07.328219Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn, scaler):\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = 0.\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        # token_type_ids = batch[\"token_type_ids\"].to(DEVICE) # not for T5 and MPNet\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        # https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            # logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5 and MPNet\n",
    "            loss = loss_fn(logits, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # logits = model(\n",
    "        #     input_ids=input_ids, \n",
    "        #     attention_mask=attention_mask,\n",
    "        #     # token_type_ids=token_type_ids\n",
    "        #     ).squeeze()\n",
    "        # loss = loss_fn(logits, labels)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            preds = F.sigmoid(logits).detach().cpu().float().numpy()\n",
    "            preds = (preds > 0.5) * 1\n",
    "            y_true = labels.detach().cpu().numpy()\n",
    "            \n",
    "            predictions += preds.tolist()\n",
    "            true_labels += y_true.tolist()\n",
    "    \n",
    "    avg_loss /= len(loader) + 1\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)    \n",
    "    \n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = 0.\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        # token_type_ids = batch[\"token_type_ids\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        # logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5 and mpnet\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        preds = F.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds = (preds > 0.5) * 1\n",
    "        y_true = labels.detach().cpu().numpy()\n",
    "        predictions += preds.tolist()\n",
    "        true_labels += y_true.tolist()\n",
    "\n",
    "    avg_loss /= len(loader)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, save_dir, epochs=10, ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): Moder for training\n",
    "        train_loader (_type_): _description_\n",
    "        val_loader (_type_): _description_\n",
    "        optimizer (_type_): _description_\n",
    "        loss_fn (_type_): _description_\n",
    "        save_dir (str): folder name to save ckpt to\n",
    "        epochs (int, optional): _description_. Defaults to 10.\n",
    "    \"\"\"\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    best_f1_val = 0\n",
    "    for e in range(epochs):\n",
    "        loss, f1, prec, rec = train_epoch(model, train_loader, optimizer, loss_fn, scaler=scaler)\n",
    "        print(f\"Train epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        loss, f1, prec, rec = eval_epoch(model, val_loader, loss_fn)\n",
    "        print(f\"Eval epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        if f1 > best_f1_val:\n",
    "            best_f1_val = f1\n",
    "            torch.save(\n",
    "                model.state_dict(), \n",
    "                os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-BEST.pth\")\n",
    "            )    \n",
    "        \n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-LAST.pth\")\n",
    "            \n",
    "            )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, evaluation and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_dev_questions = int(num_questions * train_dev_ratio)\n",
    "        train_dev_questions = all_questions[:num_train_dev_questions]\n",
    "        test_questions = set(all_questions[num_train_dev_questions:])\n",
    "        \n",
    "        num_train_questions = int(len(train_dev_questions) * train_ratio)\n",
    "        train_questions = set(train_dev_questions[:num_train_questions])\n",
    "        dev_questions = set(train_dev_questions[num_train_questions:])\n",
    "\n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "        test_df = df[df[\"question\"].isin(test_questions)]\n",
    "\n",
    "        return train_df, dev_df, test_df\n",
    "    \n",
    "def split_train_dev(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_questions = int(num_questions * train_dev_ratio)\n",
    "        train_questions = set(all_questions[:num_train_questions])\n",
    "        dev_questions = set(all_questions[num_train_questions:])\n",
    "        \n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "\n",
    "        return train_df, dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.800236Z",
     "start_time": "2024-04-18T13:17:07.356224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\experiments\\Rerun_0405\\data\\dataset.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[\"graph\"] = self.df[\"graph\"].apply(eval)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "MAX_LENGTH=200\n",
    "EPOCHS=20\n",
    "LR = 1e-4\n",
    "\n",
    "INCLUDE_GRAPH = True\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Loading dataframe for making splits\n",
    "df = pd.read_csv(train_path, sep='\\t')\n",
    "df[\"label\"] = df[\"correct\"].astype(np.float32)\n",
    "# df_train, df_dev, df_test = split_train_dev_test(df)\n",
    "df_train, df_dev = split_train_dev(df)\n",
    "\n",
    "train_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path, \n",
    "                            split='train',\n",
    "                            df_split=df_train, \n",
    "                            include_graph=INCLUDE_GRAPH,\n",
    "                            is_T5=False,\n",
    "                           )\n",
    "dev_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "                          split='val',\n",
    "                          df_split=df_dev,\n",
    "                          include_graph=INCLUDE_GRAPH,\n",
    "                          is_T5=False,\n",
    "                         )                         \n",
    "# test_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "#                            split='test',\n",
    "#                            df_split=df_test, \n",
    "#                            include_graph=INCLUDE_GRAPH,\n",
    "#                            is_T5=True,\n",
    "#                           )\n",
    "\n",
    "weights = compute_sample_weight('balanced', train_ds.labels)\n",
    "sampler = WeightedRandomSampler(weights, len(weights)) # we will oversample correct answers :)\n",
    "\n",
    "CONFIG_DATALOADER = {\"num_workers\":4, \"pin_memory\":True}\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sampler=sampler, # does not allow to use shuffle\n",
    "#     shuffle=True, \n",
    "    **CONFIG_DATALOADER\n",
    ")\n",
    "dev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)\n",
    "# test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> roger federer, novak djokovic : who's won more head - to - head tennis matches between each other, novak djokovic or roger federer? [ sep ] roger federer, significant person, novak djokovic ; roger federer, significant person, [ sep ] rafael nadal [ sep ] ; novak djokovic, significant person, roger federer ; novak djokovic, significant person, [ sep ] rafael nadal [ sep ] ; [ sep ] rafael nadal [ sep ], significant person, roger federer ; [ sep ] rafael nadal [ sep ], significant person, novak djokovic ; </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_ds[23]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> major league baseball : whose is the oldest mlb player to hit a home run? [ sep ] [ sep ] yogi berra [ sep ], league, major league baseball ; </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dev_ds[0]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.816220Z",
     "start_time": "2024-04-18T13:17:10.800236Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(params=lora_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.936413Z",
     "start_time": "2024-04-18T13:17:10.816220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQlet run - with linearized graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [04:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1 - loss: 0.349, f1: 0.831, precision: 0.789, recall: 0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:53<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 1 - loss: 0.379, f1: 0.440, precision: 0.287, recall: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:57<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 2 - loss: 0.272, f1: 0.872, precision: 0.833, recall: 0.916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:54<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 2 - loss: 0.292, f1: 0.517, precision: 0.371, recall: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:59<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 3 - loss: 0.236, f1: 0.895, precision: 0.858, recall: 0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:54<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 3 - loss: 0.279, f1: 0.528, precision: 0.389, recall: 0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:57<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 4 - loss: 0.209, f1: 0.910, precision: 0.877, recall: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:54<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 4 - loss: 0.324, f1: 0.515, precision: 0.370, recall: 0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [04:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 5 - loss: 0.190, f1: 0.920, precision: 0.888, recall: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:54<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 5 - loss: 0.251, f1: 0.568, precision: 0.451, recall: 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:59<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 6 - loss: 0.166, f1: 0.933, precision: 0.904, recall: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:54<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 6 - loss: 0.261, f1: 0.586, precision: 0.471, recall: 0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:57<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 7 - loss: 0.155, f1: 0.938, precision: 0.911, recall: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:52<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 7 - loss: 0.259, f1: 0.596, precision: 0.484, recall: 0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:49<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 8 - loss: 0.136, f1: 0.948, precision: 0.925, recall: 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 8 - loss: 0.277, f1: 0.604, precision: 0.523, recall: 0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 9 - loss: 0.133, f1: 0.948, precision: 0.925, recall: 0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 9 - loss: 0.301, f1: 0.586, precision: 0.472, recall: 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 10 - loss: 0.128, f1: 0.952, precision: 0.928, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 10 - loss: 0.275, f1: 0.610, precision: 0.530, recall: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 11 - loss: 0.119, f1: 0.957, precision: 0.936, recall: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 11 - loss: 0.263, f1: 0.621, precision: 0.539, recall: 0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 12 - loss: 0.110, f1: 0.959, precision: 0.940, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 12 - loss: 0.264, f1: 0.612, precision: 0.520, recall: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 13 - loss: 0.101, f1: 0.964, precision: 0.947, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 13 - loss: 0.284, f1: 0.626, precision: 0.563, recall: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 14 - loss: 0.099, f1: 0.964, precision: 0.949, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 14 - loss: 0.299, f1: 0.616, precision: 0.517, recall: 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:46<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 15 - loss: 0.096, f1: 0.964, precision: 0.949, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 15 - loss: 0.273, f1: 0.613, precision: 0.527, recall: 0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:45<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 16 - loss: 0.091, f1: 0.967, precision: 0.952, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 16 - loss: 0.296, f1: 0.612, precision: 0.525, recall: 0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:45<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 17 - loss: 0.080, f1: 0.973, precision: 0.959, recall: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 17 - loss: 0.329, f1: 0.618, precision: 0.542, recall: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:47<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 18 - loss: 0.081, f1: 0.972, precision: 0.957, recall: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:53<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 18 - loss: 0.326, f1: 0.627, precision: 0.555, recall: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:48<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 19 - loss: 0.076, f1: 0.973, precision: 0.962, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 19 - loss: 0.325, f1: 0.634, precision: 0.564, recall: 0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [03:47<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 20 - loss: 0.073, f1: 0.975, precision: 0.963, recall: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:51<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 20 - loss: 0.348, f1: 0.632, precision: 0.579, recall: 0.697\n",
      "CPU times: total: 8h 6min 29s\n",
      "Wall time: 1h 39min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "SAVE_DIR = f\"logs-mpnet-cl{MAX_LENGTH}-lingraph_{INCLUDE_GRAPH}-Adam\"\n",
    "\n",
    "train(\n",
    "    lora_model,\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    optimizer,  \n",
    "    loss_fn,\n",
    "    epochs=EPOCHS,\n",
    "    save_dir=SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_submit_predictions(model, tokenizer, include_graph, filename='submission.csv'):\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', include_graph=include_graph)\n",
    "    preds = []\n",
    "    for idx, data in tqdm(enumerate(eval_ds)):\n",
    "        input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        \n",
    "        logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        pred = (logit.detach().cpu().numpy() > 0) * 1\n",
    "        preds.append(pred)\n",
    "\n",
    "    df = eval_ds.df\n",
    "    df['prediction'] = preds\n",
    "    df['prediction'] = df['prediction'].astype(int)\n",
    "    df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_submit_predictions_ranked(model, tokenizer, include_graph, filename='submission.csv', is_t5=False):\n",
    "    \"\"\"based of Vika's idea - select all candidate answers for questions, select one with max prob\"\"\"\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', \n",
    "                               df_split=None,\n",
    "                               include_graph=include_graph)\n",
    "    eval_df = eval_ds.df\n",
    "    eval_df[\"correct\"] = False\n",
    "\n",
    "    for question in tqdm(eval_df['question'].unique()):\n",
    "        ids = eval_df.index[eval_df['question'] == question].tolist()\n",
    "        \n",
    "        logits = []\n",
    "        for idx in ids:\n",
    "            data = eval_ds[idx]\n",
    "            input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "            attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "            if is_t5:\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask,).squeeze()\n",
    "            else:\n",
    "                token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "            \n",
    "            \n",
    "            logits.append(logit.detach().cpu().item())\n",
    "\n",
    "        right_ans_id = ids[np.argmax(logits)]\n",
    "        eval_df.loc[right_ans_id, 'correct'] = True\n",
    "\n",
    "    eval_df['prediction'] = eval_df['correct']\n",
    "    eval_df['prediction'] = eval_df['prediction'].astype(int)\n",
    "    eval_df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:16<00:00,  7.31it/s]\n",
      "100%|██████████| 1000/1000 [02:17<00:00,  7.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import copy \n",
    "\n",
    "best_leaderboard_path = r\"C:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\all-MiniLM-L6-v2--lora-fixed_oversampling-pqlet-includegraphs.pth\"\n",
    "load_path_best = f'{SAVE_DIR}\\minilm--lora-fixed_oversampling-includegraphs-BEST.pth'\n",
    "load_path_last = f'{SAVE_DIR}\\minilm--lora-fixed_oversampling-includegraphs-LAST.pth'\n",
    "\n",
    "# Best model submission\n",
    "submission_lora_model = copy.deepcopy(lora_model)\n",
    "state_dict_loaded = torch.load(load_path_best)\n",
    "submission_lora_model.load_state_dict(state_dict_loaded)\n",
    "make_submit_predictions_ranked(\n",
    "    submission_lora_model,\n",
    "    tokenizer,\n",
    "    include_graph=INCLUDE_GRAPH,\n",
    "    filename=f\"{SAVE_DIR}/{SAVE_DIR}-submission_best.csv\",\n",
    "    is_t5=True\n",
    ")\n",
    "\n",
    "# Last model submission\n",
    "submission_lora_model = copy.deepcopy(lora_model)\n",
    "state_dict_loaded = torch.load(load_path_last)\n",
    "submission_lora_model.load_state_dict(state_dict_loaded)\n",
    "make_submit_predictions_ranked(\n",
    "    submission_lora_model,\n",
    "    tokenizer,\n",
    "    include_graph=INCLUDE_GRAPH,\n",
    "    filename=f\"{SAVE_DIR}/{SAVE_DIR}-submission_last.csv\",\n",
    "    is_t5=True\n",
    ")\n",
    "\n",
    "# # Best model according to the public leaderboard\n",
    "# submission_lora_model = copy.deepcopy(lora_model)\n",
    "# state_dict_loaded = torch.load(best_leaderboard_path)\n",
    "# submission_lora_model.model.load_state_dict(state_dict_loaded)\n",
    "# make_submit_predictions_ranked(\n",
    "#     submission_lora_model,\n",
    "#     tokenizer,\n",
    "#     include_graph=INCLUDE_GRAPH,\n",
    "#     filename=f\"{SAVE_DIR}/submission_best.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpttv-jup",
   "language": "python",
   "name": "cmpttv-jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

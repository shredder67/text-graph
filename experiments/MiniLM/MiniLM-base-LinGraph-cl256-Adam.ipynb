{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:02.658384Z",
     "start_time": "2024-04-18T13:16:58.094390Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, T5ForConditionalGeneration\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.246414Z",
     "start_time": "2024-04-18T13:17:02.658384Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.278409Z",
     "start_time": "2024-04-18T13:17:03.246414Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '../../data/tsv/train.tsv'\n",
    "test_path = '../../data/tsv/test.tsv'\n",
    "\n",
    "from data.dataset import TextGraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep and finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:06.272205Z",
     "start_time": "2024-04-18T13:17:03.282394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_bert = AutoModel.from_pretrained(model_name,)\n",
    "\n",
    "# model_name = \"whaleloops/phrase-bert\"\n",
    "# model_name = \"DeepPavlov/t5-wikidata5M-with-neighbors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.072235Z",
     "start_time": "2024-04-18T13:17:06.272205Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_bert):\n",
    "        super().__init__()\n",
    "        self.bert_backbone = pretrained_bert\n",
    "        self.hidden_size = pretrained_bert.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_size // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert_backbone(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state  # Access the last hidden states\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the [CLS] token representation\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "model = QuestionClassifier(\n",
    "    pretrained_bert\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.088222Z",
     "start_time": "2024-04-18T13:17:07.072235Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.292235Z",
     "start_time": "2024-04-18T13:17:07.088222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147456 || all params: 22934785 || trainable%: 0.6429360467080899\n",
      "Unfreezing head\n",
      "trainable params: 221569 || all params: 22934785 || trainable%: 0.9660827428728894\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, LoraModel, get_peft_model\n",
    "\n",
    "LORA_RANK=16 # 16 default\n",
    "LORA_ALPHA=32.\n",
    "LORA_DROPOUT=1e-1\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=LORA_RANK,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\"query\", \"value\"], # for minilm\n",
    "    # target_modules=[\"q\", \"v\"], # T5 [\"q\", \"v\", \"k\", \"o\"]\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    use_rslora=True,\n",
    ")\n",
    "\n",
    "lora_model = LoraModel(model, config, \"default\")\n",
    "##  make sure to first wrap the base model by calling get_peft_model before wrapping it in PyTorch\n",
    "# lora_model = get_peft_model(model, config)\n",
    "\n",
    "print_trainable_parameters(lora_model)\n",
    "\n",
    "print('Unfreezing head')\n",
    "# Unfreeze the clf head\n",
    "for p in lora_model.head.parameters():\n",
    "    p.requires_grad = True\n",
    "print_trainable_parameters(lora_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the parameters are frozen\n",
    "\n",
    "# for n, p in lora_model.named_parameters():\n",
    "#     print(p.requires_grad, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.356224Z",
     "start_time": "2024-04-18T13:17:07.328219Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn, scaler):\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = 0.\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(DEVICE) # not for T5\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        # # https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training\n",
    "        # with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        #     logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        #     # logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5\n",
    "        #     loss = loss_fn(logits, labels)\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        \n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            preds = F.sigmoid(logits).detach().cpu().float().numpy()\n",
    "            preds = (preds > 0.5) * 1\n",
    "            y_true = labels.detach().cpu().numpy()\n",
    "            \n",
    "            predictions += preds.tolist()\n",
    "            true_labels += y_true.tolist()\n",
    "    \n",
    "    avg_loss /= len(loader) + 1\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)    \n",
    "    \n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = 0.\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        # logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        preds = F.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds = (preds > 0.5) * 1\n",
    "        y_true = labels.detach().cpu().numpy()\n",
    "        predictions += preds.tolist()\n",
    "        true_labels += y_true.tolist()\n",
    "\n",
    "    avg_loss /= len(loader)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, save_dir, epochs=10, ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): Moder for training\n",
    "        train_loader (_type_): _description_\n",
    "        val_loader (_type_): _description_\n",
    "        optimizer (_type_): _description_\n",
    "        loss_fn (_type_): _description_\n",
    "        save_dir (str): folder name to save ckpt to\n",
    "        epochs (int, optional): _description_. Defaults to 10.\n",
    "    \"\"\"\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    best_f1_val = 0\n",
    "    for e in range(epochs):\n",
    "        loss, f1, prec, rec = train_epoch(model, train_loader, optimizer, loss_fn, scaler=scaler)\n",
    "        print(f\"Train epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        loss, f1, prec, rec = eval_epoch(model, val_loader, loss_fn)\n",
    "        print(f\"Eval epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        if f1 > best_f1_val:\n",
    "            best_f1_val = f1\n",
    "            torch.save(\n",
    "                model.state_dict(), \n",
    "                os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-BEST.pth\")\n",
    "            )    \n",
    "        \n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-LAST.pth\")\n",
    "            \n",
    "            )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, evaluation and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_dev_questions = int(num_questions * train_dev_ratio)\n",
    "        train_dev_questions = all_questions[:num_train_dev_questions]\n",
    "        test_questions = set(all_questions[num_train_dev_questions:])\n",
    "        \n",
    "        num_train_questions = int(len(train_dev_questions) * train_ratio)\n",
    "        train_questions = set(train_dev_questions[:num_train_questions])\n",
    "        dev_questions = set(train_dev_questions[num_train_questions:])\n",
    "\n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "        test_df = df[df[\"question\"].isin(test_questions)]\n",
    "\n",
    "        return train_df, dev_df, test_df\n",
    "    \n",
    "def split_train_dev(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_questions = int(num_questions * train_dev_ratio)\n",
    "        train_questions = set(all_questions[:num_train_questions])\n",
    "        dev_questions = set(all_questions[num_train_questions:])\n",
    "        \n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "\n",
    "        return train_df, dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.800236Z",
     "start_time": "2024-04-18T13:17:07.356224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\experiments\\Rerun_0405\\data\\dataset.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[\"graph\"] = self.df[\"graph\"].apply(eval)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "MAX_LENGTH=256\n",
    "EPOCHS=50\n",
    "LR = 3e-4\n",
    "\n",
    "INCLUDE_GRAPH = True\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Loading dataframe for making splits\n",
    "df = pd.read_csv(train_path, sep='\\t')\n",
    "df[\"label\"] = df[\"correct\"].astype(np.float32)\n",
    "# df_train, df_dev, df_test = split_train_dev_test(df)\n",
    "df_train, df_dev = split_train_dev(df)\n",
    "\n",
    "train_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path, \n",
    "                            split='train',\n",
    "                            df_split=df_train, \n",
    "                            include_graph=INCLUDE_GRAPH,\n",
    "                            is_T5=False,\n",
    "                           )\n",
    "dev_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "                          split='val',\n",
    "                          df_split=df_dev,\n",
    "                          include_graph=INCLUDE_GRAPH,\n",
    "                          is_T5=False,\n",
    "                         )                         \n",
    "# test_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "#                            split='test',\n",
    "#                            df_split=df_test, \n",
    "#                            include_graph=INCLUDE_GRAPH,\n",
    "#                            is_T5=True,\n",
    "#                           )\n",
    "\n",
    "weights = compute_sample_weight('balanced', train_ds.labels)\n",
    "sampler = WeightedRandomSampler(weights, len(weights)) # we will oversample correct answers :)\n",
    "\n",
    "CONFIG_DATALOADER = {\"num_workers\":4, \"pin_memory\":True}\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sampler=sampler, # does not allow to use shuffle\n",
    "#     shuffle=True, \n",
    "    **CONFIG_DATALOADER\n",
    ")\n",
    "dev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)\n",
    "# test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] roger federer, novak djokovic : who's won more head - to - head tennis matches between each other, novak djokovic or roger federer? [SEP] roger federer, significant person, novak djokovic ; roger federer, significant person, [SEP] rafael nadal [SEP] ; novak djokovic, significant person, roger federer ; novak djokovic, significant person, [SEP] rafael nadal [SEP] ; [SEP] rafael nadal [SEP], significant person, roger federer ; [SEP] rafael nadal [SEP], significant person, novak djokovic ; [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_ds[23]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] major league baseball : whose is the oldest mlb player to hit a home run? [SEP] [SEP] yogi berra [SEP], league, major league baseball ; [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dev_ds[0]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.816220Z",
     "start_time": "2024-04-18T13:17:10.800236Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(params=lora_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.936413Z",
     "start_time": "2024-04-18T13:17:10.816220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQlet run - with linearized graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniLM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1 - loss: 0.344, f1: 0.830, precision: 0.792, recall: 0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 1 - loss: 0.375, f1: 0.433, precision: 0.283, recall: 0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 2 - loss: 0.275, f1: 0.870, precision: 0.832, recall: 0.910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 2 - loss: 0.324, f1: 0.479, precision: 0.333, recall: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:06<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 3 - loss: 0.247, f1: 0.887, precision: 0.852, recall: 0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 3 - loss: 0.360, f1: 0.476, precision: 0.325, recall: 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 4 - loss: 0.231, f1: 0.899, precision: 0.862, recall: 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 4 - loss: 0.298, f1: 0.516, precision: 0.383, recall: 0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 5 - loss: 0.206, f1: 0.911, precision: 0.880, recall: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 5 - loss: 0.295, f1: 0.530, precision: 0.396, recall: 0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 6 - loss: 0.190, f1: 0.918, precision: 0.889, recall: 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 6 - loss: 0.274, f1: 0.549, precision: 0.432, recall: 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 7 - loss: 0.176, f1: 0.928, precision: 0.901, recall: 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 7 - loss: 0.343, f1: 0.528, precision: 0.391, recall: 0.810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 8 - loss: 0.163, f1: 0.932, precision: 0.908, recall: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 8 - loss: 0.277, f1: 0.567, precision: 0.455, recall: 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 9 - loss: 0.152, f1: 0.940, precision: 0.916, recall: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 9 - loss: 0.300, f1: 0.568, precision: 0.469, recall: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 10 - loss: 0.143, f1: 0.943, precision: 0.920, recall: 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 10 - loss: 0.347, f1: 0.528, precision: 0.392, recall: 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 11 - loss: 0.142, f1: 0.945, precision: 0.922, recall: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 11 - loss: 0.294, f1: 0.566, precision: 0.458, recall: 0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 12 - loss: 0.132, f1: 0.949, precision: 0.929, recall: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 12 - loss: 0.321, f1: 0.575, precision: 0.465, recall: 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 13 - loss: 0.127, f1: 0.951, precision: 0.933, recall: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 13 - loss: 0.310, f1: 0.574, precision: 0.473, recall: 0.730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 14 - loss: 0.123, f1: 0.953, precision: 0.935, recall: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 14 - loss: 0.329, f1: 0.542, precision: 0.422, recall: 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 15 - loss: 0.116, f1: 0.956, precision: 0.938, recall: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 15 - loss: 0.343, f1: 0.563, precision: 0.453, recall: 0.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 16 - loss: 0.113, f1: 0.958, precision: 0.941, recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 16 - loss: 0.272, f1: 0.577, precision: 0.484, recall: 0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 17 - loss: 0.110, f1: 0.960, precision: 0.945, recall: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 17 - loss: 0.341, f1: 0.568, precision: 0.467, recall: 0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 18 - loss: 0.104, f1: 0.962, precision: 0.948, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 18 - loss: 0.315, f1: 0.583, precision: 0.516, recall: 0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 19 - loss: 0.101, f1: 0.964, precision: 0.950, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 19 - loss: 0.346, f1: 0.578, precision: 0.472, recall: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 20 - loss: 0.101, f1: 0.964, precision: 0.950, recall: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 20 - loss: 0.331, f1: 0.584, precision: 0.491, recall: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 21 - loss: 0.096, f1: 0.965, precision: 0.951, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 21 - loss: 0.328, f1: 0.584, precision: 0.491, recall: 0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 22 - loss: 0.098, f1: 0.963, precision: 0.949, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 22 - loss: 0.375, f1: 0.580, precision: 0.487, recall: 0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 23 - loss: 0.093, f1: 0.967, precision: 0.953, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 23 - loss: 0.329, f1: 0.597, precision: 0.534, recall: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 24 - loss: 0.087, f1: 0.967, precision: 0.956, recall: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 24 - loss: 0.317, f1: 0.585, precision: 0.515, recall: 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 25 - loss: 0.087, f1: 0.968, precision: 0.957, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 25 - loss: 0.305, f1: 0.582, precision: 0.500, recall: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 26 - loss: 0.087, f1: 0.968, precision: 0.957, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 26 - loss: 0.315, f1: 0.582, precision: 0.509, recall: 0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:06<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 27 - loss: 0.091, f1: 0.966, precision: 0.954, recall: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 27 - loss: 0.346, f1: 0.565, precision: 0.462, recall: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 28 - loss: 0.088, f1: 0.968, precision: 0.956, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 28 - loss: 0.334, f1: 0.580, precision: 0.504, recall: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 29 - loss: 0.082, f1: 0.970, precision: 0.959, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 29 - loss: 0.343, f1: 0.575, precision: 0.491, recall: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 30 - loss: 0.083, f1: 0.970, precision: 0.959, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 30 - loss: 0.292, f1: 0.593, precision: 0.527, recall: 0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 31 - loss: 0.084, f1: 0.970, precision: 0.959, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 31 - loss: 0.373, f1: 0.570, precision: 0.473, recall: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 32 - loss: 0.078, f1: 0.971, precision: 0.961, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 32 - loss: 0.360, f1: 0.598, precision: 0.572, recall: 0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 33 - loss: 0.079, f1: 0.972, precision: 0.963, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 33 - loss: 0.350, f1: 0.590, precision: 0.521, recall: 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 34 - loss: 0.077, f1: 0.972, precision: 0.961, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 34 - loss: 0.315, f1: 0.586, precision: 0.506, recall: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 35 - loss: 0.078, f1: 0.972, precision: 0.962, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 35 - loss: 0.380, f1: 0.590, precision: 0.525, recall: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 36 - loss: 0.070, f1: 0.975, precision: 0.966, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 36 - loss: 0.373, f1: 0.600, precision: 0.530, recall: 0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 37 - loss: 0.075, f1: 0.974, precision: 0.965, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 37 - loss: 0.326, f1: 0.604, precision: 0.566, recall: 0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 38 - loss: 0.073, f1: 0.974, precision: 0.965, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 38 - loss: 0.354, f1: 0.569, precision: 0.469, recall: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 39 - loss: 0.072, f1: 0.975, precision: 0.966, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 39 - loss: 0.357, f1: 0.604, precision: 0.569, recall: 0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 40 - loss: 0.074, f1: 0.973, precision: 0.964, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 40 - loss: 0.338, f1: 0.601, precision: 0.534, recall: 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 41 - loss: 0.072, f1: 0.974, precision: 0.964, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 41 - loss: 0.403, f1: 0.590, precision: 0.501, recall: 0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 42 - loss: 0.070, f1: 0.975, precision: 0.968, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 42 - loss: 0.345, f1: 0.587, precision: 0.499, recall: 0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 43 - loss: 0.071, f1: 0.975, precision: 0.967, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 43 - loss: 0.367, f1: 0.580, precision: 0.491, recall: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:07<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 44 - loss: 0.069, f1: 0.975, precision: 0.967, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 44 - loss: 0.320, f1: 0.603, precision: 0.528, recall: 0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 45 - loss: 0.066, f1: 0.976, precision: 0.969, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 45 - loss: 0.319, f1: 0.622, precision: 0.575, recall: 0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:11<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 46 - loss: 0.069, f1: 0.975, precision: 0.967, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 46 - loss: 0.348, f1: 0.591, precision: 0.535, recall: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 47 - loss: 0.068, f1: 0.975, precision: 0.966, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 47 - loss: 0.382, f1: 0.583, precision: 0.502, recall: 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 48 - loss: 0.070, f1: 0.975, precision: 0.967, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 48 - loss: 0.369, f1: 0.593, precision: 0.503, recall: 0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:06<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 49 - loss: 0.064, f1: 0.977, precision: 0.970, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 49 - loss: 0.361, f1: 0.595, precision: 0.527, recall: 0.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 50 - loss: 0.067, f1: 0.976, precision: 0.967, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 50 - loss: 0.347, f1: 0.588, precision: 0.506, recall: 0.703\n",
      "CPU times: total: 1h 55min 39s\n",
      "Wall time: 2h 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "SAVE_DIR = f\"logs-minilm-cl{MAX_LENGTH}-lingraph_{INCLUDE_GRAPH}-Adam\"\n",
    "\n",
    "train(\n",
    "    lora_model,\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    optimizer,  \n",
    "    loss_fn,\n",
    "    epochs=EPOCHS,\n",
    "    save_dir=SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_submit_predictions(model, tokenizer, include_graph, filename='submission.csv'):\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', include_graph=include_graph)\n",
    "    preds = []\n",
    "    for idx, data in tqdm(enumerate(eval_ds)):\n",
    "        input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        \n",
    "        logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        pred = (logit.detach().cpu().numpy() > 0) * 1\n",
    "        preds.append(pred)\n",
    "\n",
    "    df = eval_ds.df\n",
    "    df['prediction'] = preds\n",
    "    df['prediction'] = df['prediction'].astype(int)\n",
    "    df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_submit_predictions_ranked(model, tokenizer, include_graph, filename='submission.csv', is_t5=False):\n",
    "    \"\"\"based of Vika's idea - select all candidate answers for questions, select one with max prob\"\"\"\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', \n",
    "                               df_split=None,\n",
    "                               include_graph=include_graph)\n",
    "    eval_df = eval_ds.df\n",
    "    eval_df[\"correct\"] = False\n",
    "\n",
    "    for question in tqdm(eval_df['question'].unique()):\n",
    "        ids = eval_df.index[eval_df['question'] == question].tolist()\n",
    "        \n",
    "        logits = []\n",
    "        for idx in ids:\n",
    "            data = eval_ds[idx]\n",
    "            input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "            attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "            if is_t5:\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask,).squeeze()\n",
    "            else:\n",
    "                token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "            \n",
    "            \n",
    "            logits.append(logit.detach().cpu().item())\n",
    "\n",
    "        right_ans_id = ids[np.argmax(logits)]\n",
    "        eval_df.loc[right_ans_id, 'correct'] = True\n",
    "\n",
    "    eval_df['prediction'] = eval_df['correct']\n",
    "    eval_df['prediction'] = eval_df['prediction'].astype(int)\n",
    "    eval_df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:49<00:00, 20.22it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import copy \n",
    "\n",
    "best_leaderboard_path = r\"C:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\all-MiniLM-L6-v2--lora-fixed_oversampling-pqlet-includegraphs.pth\"\n",
    "load_path_best = f'{SAVE_DIR}\\minilm--lora-fixed_oversampling-includegraphs-BEST.pth'\n",
    "load_path_last = f'{SAVE_DIR}\\minilm--lora-fixed_oversampling-includegraphs-LAST.pth'\n",
    "\n",
    "# Best model submission\n",
    "submission_lora_model = copy.deepcopy(lora_model)\n",
    "state_dict_loaded = torch.load(load_path_best)\n",
    "submission_lora_model.load_state_dict(state_dict_loaded)\n",
    "make_submit_predictions_ranked(\n",
    "    submission_lora_model,\n",
    "    tokenizer,\n",
    "    include_graph=INCLUDE_GRAPH,\n",
    "    filename=f\"{SAVE_DIR}/{SAVE_DIR}-submission_best.csv\",\n",
    ")\n",
    "\n",
    "# Last model submission\n",
    "submission_lora_model = copy.deepcopy(lora_model)\n",
    "state_dict_loaded = torch.load(load_path_last)\n",
    "submission_lora_model.load_state_dict(state_dict_loaded)\n",
    "make_submit_predictions_ranked(\n",
    "    submission_lora_model,\n",
    "    tokenizer,\n",
    "    include_graph=INCLUDE_GRAPH,\n",
    "    filename=f\"{SAVE_DIR}/{SAVE_DIR}-submission_last.csv\",\n",
    ")\n",
    "\n",
    "# # Best model according to the public leaderboard\n",
    "# submission_lora_model = copy.deepcopy(lora_model)\n",
    "# state_dict_loaded = torch.load(best_leaderboard_path)\n",
    "# submission_lora_model.model.load_state_dict(state_dict_loaded)\n",
    "# make_submit_predictions_ranked(\n",
    "#     submission_lora_model,\n",
    "#     tokenizer,\n",
    "#     include_graph=INCLUDE_GRAPH,\n",
    "#     filename=f\"{SAVE_DIR}/submission_best.csv\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpttv-jup",
   "language": "python",
   "name": "cmpttv-jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:02.658384Z",
     "start_time": "2024-04-18T13:16:58.094390Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, T5ForConditionalGeneration\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.246414Z",
     "start_time": "2024-04-18T13:17:02.658384Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:03.278409Z",
     "start_time": "2024-04-18T13:17:03.246414Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '../../data/tsv/train.tsv'\n",
    "test_path = '../../data/tsv/test.tsv'\n",
    "\n",
    "from data.dataset import TextGraphDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep and finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:06.272205Z",
     "start_time": "2024-04-18T13:17:03.282394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pretrained_bert = AutoModel.from_pretrained(model_name,)\n",
    "\n",
    "# model_name = \"whaleloops/phrase-bert\"\n",
    "# model_name = \"DeepPavlov/t5-wikidata5M-with-neighbors\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.072235Z",
     "start_time": "2024-04-18T13:17:06.272205Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuestionClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_bert):\n",
    "        super().__init__()\n",
    "        self.bert_backbone = pretrained_bert\n",
    "        self.hidden_size = pretrained_bert.config.hidden_size\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_size // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert_backbone(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state  # Access the last hidden states\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # Take the [CLS] token representation\n",
    "        logits = self.head(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "model = QuestionClassifier(\n",
    "    pretrained_bert\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.088222Z",
     "start_time": "2024-04-18T13:17:07.072235Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.292235Z",
     "start_time": "2024-04-18T13:17:07.088222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147456 || all params: 22934785 || trainable%: 0.6429360467080899\n",
      "Unfreezing head\n",
      "trainable params: 221569 || all params: 22934785 || trainable%: 0.9660827428728894\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, LoraModel, get_peft_model\n",
    "\n",
    "LORA_RANK=16 # 16 default\n",
    "LORA_ALPHA=32.\n",
    "LORA_DROPOUT=1e-1\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=LORA_RANK,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=[\"query\", \"value\"], # for minilm\n",
    "    # target_modules=[\"q\", \"v\"], # T5 [\"q\", \"v\", \"k\", \"o\"]\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    use_rslora=True,\n",
    ")\n",
    "\n",
    "lora_model = LoraModel(model, config, \"default\")\n",
    "##  make sure to first wrap the base model by calling get_peft_model before wrapping it in PyTorch\n",
    "# lora_model = get_peft_model(model, config)\n",
    "\n",
    "print_trainable_parameters(lora_model)\n",
    "\n",
    "print('Unfreezing head')\n",
    "# Unfreeze the clf head\n",
    "for p in lora_model.head.parameters():\n",
    "    p.requires_grad = True\n",
    "print_trainable_parameters(lora_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the parameters are frozen\n",
    "\n",
    "# for n, p in lora_model.named_parameters():\n",
    "#     print(p.requires_grad, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:07.356224Z",
     "start_time": "2024-04-18T13:17:07.328219Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn, scaler):\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = 0.\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(DEVICE) # not for T5\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        # # https://pytorch.org/docs/stable/notes/amp_examples.html#typical-mixed-precision-training\n",
    "        # with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        #     logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        #     # logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5\n",
    "        #     loss = loss_fn(logits, labels)\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "        \n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        with torch.no_grad():\n",
    "            preds = F.sigmoid(logits).detach().cpu().float().numpy()\n",
    "            preds = (preds > 0.5) * 1\n",
    "            y_true = labels.detach().cpu().numpy()\n",
    "            \n",
    "            predictions += preds.tolist()\n",
    "            true_labels += y_true.tolist()\n",
    "    \n",
    "    avg_loss /= len(loader) + 1\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)    \n",
    "    \n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    avg_loss = 0.\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE).float()\n",
    "        \n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        # logits = model(input_ids=input_ids, attention_mask=attention_mask).squeeze() # for T5\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        preds = F.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds = (preds > 0.5) * 1\n",
    "        y_true = labels.detach().cpu().numpy()\n",
    "        predictions += preds.tolist()\n",
    "        true_labels += y_true.tolist()\n",
    "\n",
    "    avg_loss /= len(loader)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    return avg_loss, f1, precision, recall\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, loss_fn, save_dir, epochs=10, ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): Moder for training\n",
    "        train_loader (_type_): _description_\n",
    "        val_loader (_type_): _description_\n",
    "        optimizer (_type_): _description_\n",
    "        loss_fn (_type_): _description_\n",
    "        save_dir (str): folder name to save ckpt to\n",
    "        epochs (int, optional): _description_. Defaults to 10.\n",
    "    \"\"\"\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    best_f1_val = 0\n",
    "    for e in range(epochs):\n",
    "        loss, f1, prec, rec = train_epoch(model, train_loader, optimizer, loss_fn, scaler=scaler)\n",
    "        print(f\"Train epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        loss, f1, prec, rec = eval_epoch(model, val_loader, loss_fn)\n",
    "        print(f\"Eval epoch {e + 1} - loss: {loss:.3f}, f1: {f1:.3f}, precision: {prec:.3f}, recall: {rec:.3f}\")\n",
    "        \n",
    "        if f1 > best_f1_val:\n",
    "            best_f1_val = f1\n",
    "            torch.save(\n",
    "                model.state_dict(), \n",
    "                os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-BEST.pth\")\n",
    "            )    \n",
    "        \n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(save_dir,\"minilm--lora-fixed_oversampling-includegraphs-LAST.pth\")\n",
    "            \n",
    "            )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, evaluation and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_dev_test(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_dev_questions = int(num_questions * train_dev_ratio)\n",
    "        train_dev_questions = all_questions[:num_train_dev_questions]\n",
    "        test_questions = set(all_questions[num_train_dev_questions:])\n",
    "        \n",
    "        num_train_questions = int(len(train_dev_questions) * train_ratio)\n",
    "        train_questions = set(train_dev_questions[:num_train_questions])\n",
    "        dev_questions = set(train_dev_questions[num_train_questions:])\n",
    "\n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "        test_df = df[df[\"question\"].isin(test_questions)]\n",
    "\n",
    "        return train_df, dev_df, test_df\n",
    "    \n",
    "def split_train_dev(df: pd.DataFrame):\n",
    "        all_questions = list(df[\"question\"].unique())\n",
    "        num_questions = len(all_questions)\n",
    "        random.shuffle(all_questions)\n",
    "\n",
    "        train_dev_ratio = 0.8\n",
    "        train_ratio = 0.9\n",
    "        num_train_questions = int(num_questions * train_dev_ratio)\n",
    "        train_questions = set(all_questions[:num_train_questions])\n",
    "        dev_questions = set(all_questions[num_train_questions:])\n",
    "        \n",
    "        train_df = df[df[\"question\"].isin(train_questions)]\n",
    "        dev_df = df[df[\"question\"].isin(dev_questions)]\n",
    "\n",
    "        return train_df, dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.800236Z",
     "start_time": "2024-04-18T13:17:07.356224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\experiments\\Rerun_0405\\data\\dataset.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df[\"graph\"] = self.df[\"graph\"].apply(eval)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "MAX_LENGTH=256\n",
    "EPOCHS=50\n",
    "LR = 3e-4\n",
    "\n",
    "INCLUDE_GRAPH = True\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Loading dataframe for making splits\n",
    "df = pd.read_csv(train_path, sep='\\t')\n",
    "df[\"label\"] = df[\"correct\"].astype(np.float32)\n",
    "# df_train, df_dev, df_test = split_train_dev_test(df)\n",
    "df_train, df_dev = split_train_dev(df)\n",
    "\n",
    "train_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path, \n",
    "                            split='train',\n",
    "                            df_split=df_train, \n",
    "                            include_graph=INCLUDE_GRAPH,\n",
    "                            is_T5=False,\n",
    "                           )\n",
    "dev_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "                          split='val',\n",
    "                          df_split=df_dev,\n",
    "                          include_graph=INCLUDE_GRAPH,\n",
    "                          is_T5=False,\n",
    "                         )                         \n",
    "# test_ds = TextGraphDataset(tokenizer, MAX_LENGTH, train_path=train_path, test_path=test_path,\n",
    "#                            split='test',\n",
    "#                            df_split=df_test, \n",
    "#                            include_graph=INCLUDE_GRAPH,\n",
    "#                            is_T5=True,\n",
    "#                           )\n",
    "\n",
    "weights = compute_sample_weight('balanced', train_ds.labels)\n",
    "sampler = WeightedRandomSampler(weights, len(weights)) # we will oversample correct answers :)\n",
    "\n",
    "CONFIG_DATALOADER = {\"num_workers\":4, \"pin_memory\":True}\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    sampler=sampler, # does not allow to use shuffle\n",
    "#     shuffle=True, \n",
    "    **CONFIG_DATALOADER\n",
    ")\n",
    "dev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)\n",
    "# test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, **CONFIG_DATALOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] roger federer, novak djokovic : who's won more head - to - head tennis matches between each other, novak djokovic or roger federer? [SEP] roger federer, significant person, novak djokovic ; roger federer, significant person, [SEP] rafael nadal [SEP] ; novak djokovic, significant person, roger federer ; novak djokovic, significant person, [SEP] rafael nadal [SEP] ; [SEP] rafael nadal [SEP], significant person, roger federer ; [SEP] rafael nadal [SEP], significant person, novak djokovic ; [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_ds[23]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] major league baseball : whose is the oldest mlb player to hit a home run? [SEP] [SEP] yogi berra [SEP], league, major league baseball ; [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dev_ds[0]['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.816220Z",
     "start_time": "2024-04-18T13:17:10.800236Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(params=lora_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T13:17:10.936413Z",
     "start_time": "2024-04-18T13:17:10.816220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQlet run - with linearized graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniLM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1 - loss: 0.344, f1: 0.830, precision: 0.792, recall: 0.872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 1 - loss: 0.350, f1: 0.452, precision: 0.301, recall: 0.913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:03<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 2 - loss: 0.276, f1: 0.870, precision: 0.833, recall: 0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 2 - loss: 0.316, f1: 0.480, precision: 0.334, recall: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:22<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 3 - loss: 0.247, f1: 0.886, precision: 0.851, recall: 0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:52<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 3 - loss: 0.388, f1: 0.458, precision: 0.307, recall: 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [05:43<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 4 - loss: 0.231, f1: 0.899, precision: 0.862, recall: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 4 - loss: 0.320, f1: 0.515, precision: 0.375, recall: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 5 - loss: 0.208, f1: 0.908, precision: 0.877, recall: 0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 5 - loss: 0.313, f1: 0.508, precision: 0.367, recall: 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:09<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 6 - loss: 0.191, f1: 0.919, precision: 0.889, recall: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 6 - loss: 0.267, f1: 0.563, precision: 0.455, recall: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 7 - loss: 0.178, f1: 0.925, precision: 0.897, recall: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 7 - loss: 0.346, f1: 0.511, precision: 0.373, recall: 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 8 - loss: 0.166, f1: 0.932, precision: 0.906, recall: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 8 - loss: 0.307, f1: 0.551, precision: 0.429, recall: 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:06<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 9 - loss: 0.154, f1: 0.939, precision: 0.914, recall: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 9 - loss: 0.306, f1: 0.570, precision: 0.458, recall: 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 10 - loss: 0.146, f1: 0.942, precision: 0.919, recall: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 10 - loss: 0.305, f1: 0.558, precision: 0.436, recall: 0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 11 - loss: 0.144, f1: 0.943, precision: 0.921, recall: 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 11 - loss: 0.355, f1: 0.551, precision: 0.422, recall: 0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 12 - loss: 0.136, f1: 0.946, precision: 0.925, recall: 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 12 - loss: 0.307, f1: 0.551, precision: 0.420, recall: 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 13 - loss: 0.127, f1: 0.950, precision: 0.931, recall: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 13 - loss: 0.305, f1: 0.580, precision: 0.475, recall: 0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 14 - loss: 0.122, f1: 0.953, precision: 0.936, recall: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 14 - loss: 0.308, f1: 0.577, precision: 0.477, recall: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 15 - loss: 0.120, f1: 0.954, precision: 0.937, recall: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 15 - loss: 0.345, f1: 0.560, precision: 0.448, recall: 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 16 - loss: 0.112, f1: 0.957, precision: 0.940, recall: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 16 - loss: 0.297, f1: 0.573, precision: 0.483, recall: 0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 17 - loss: 0.113, f1: 0.958, precision: 0.943, recall: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 17 - loss: 0.343, f1: 0.569, precision: 0.456, recall: 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 18 - loss: 0.105, f1: 0.961, precision: 0.947, recall: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 18 - loss: 0.302, f1: 0.590, precision: 0.518, recall: 0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 19 - loss: 0.104, f1: 0.962, precision: 0.947, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 19 - loss: 0.347, f1: 0.568, precision: 0.457, recall: 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 20 - loss: 0.100, f1: 0.963, precision: 0.950, recall: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 20 - loss: 0.364, f1: 0.567, precision: 0.456, recall: 0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 21 - loss: 0.099, f1: 0.963, precision: 0.949, recall: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 21 - loss: 0.349, f1: 0.588, precision: 0.514, recall: 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 22 - loss: 0.097, f1: 0.964, precision: 0.951, recall: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 22 - loss: 0.373, f1: 0.577, precision: 0.486, recall: 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 23 - loss: 0.096, f1: 0.965, precision: 0.951, recall: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 23 - loss: 0.323, f1: 0.598, precision: 0.548, recall: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 24 - loss: 0.090, f1: 0.967, precision: 0.955, recall: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 24 - loss: 0.329, f1: 0.595, precision: 0.541, recall: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:09<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 25 - loss: 0.089, f1: 0.968, precision: 0.955, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 25 - loss: 0.366, f1: 0.580, precision: 0.491, recall: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 26 - loss: 0.090, f1: 0.967, precision: 0.955, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 26 - loss: 0.316, f1: 0.600, precision: 0.551, recall: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 27 - loss: 0.090, f1: 0.968, precision: 0.955, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 27 - loss: 0.350, f1: 0.567, precision: 0.463, recall: 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 28 - loss: 0.087, f1: 0.969, precision: 0.958, recall: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 28 - loss: 0.352, f1: 0.590, precision: 0.506, recall: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:05<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 29 - loss: 0.083, f1: 0.970, precision: 0.959, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 29 - loss: 0.352, f1: 0.581, precision: 0.481, recall: 0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 30 - loss: 0.082, f1: 0.970, precision: 0.959, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 30 - loss: 0.328, f1: 0.591, precision: 0.556, recall: 0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 31 - loss: 0.084, f1: 0.971, precision: 0.960, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 31 - loss: 0.356, f1: 0.583, precision: 0.498, recall: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 32 - loss: 0.077, f1: 0.971, precision: 0.961, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 32 - loss: 0.389, f1: 0.589, precision: 0.502, recall: 0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 33 - loss: 0.078, f1: 0.971, precision: 0.961, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 33 - loss: 0.363, f1: 0.599, precision: 0.523, recall: 0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 34 - loss: 0.078, f1: 0.971, precision: 0.961, recall: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 34 - loss: 0.360, f1: 0.593, precision: 0.514, recall: 0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 35 - loss: 0.075, f1: 0.974, precision: 0.964, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 35 - loss: 0.412, f1: 0.569, precision: 0.479, recall: 0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 36 - loss: 0.073, f1: 0.974, precision: 0.965, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 36 - loss: 0.352, f1: 0.585, precision: 0.495, recall: 0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 37 - loss: 0.073, f1: 0.975, precision: 0.966, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 37 - loss: 0.355, f1: 0.593, precision: 0.518, recall: 0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 38 - loss: 0.073, f1: 0.974, precision: 0.965, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 38 - loss: 0.377, f1: 0.591, precision: 0.513, recall: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 39 - loss: 0.069, f1: 0.975, precision: 0.968, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 39 - loss: 0.382, f1: 0.596, precision: 0.595, recall: 0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 40 - loss: 0.073, f1: 0.974, precision: 0.965, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 40 - loss: 0.337, f1: 0.602, precision: 0.523, recall: 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 41 - loss: 0.072, f1: 0.973, precision: 0.965, recall: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 41 - loss: 0.345, f1: 0.601, precision: 0.543, recall: 0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 42 - loss: 0.071, f1: 0.976, precision: 0.967, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 42 - loss: 0.342, f1: 0.589, precision: 0.505, recall: 0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 43 - loss: 0.065, f1: 0.977, precision: 0.969, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 43 - loss: 0.385, f1: 0.599, precision: 0.529, recall: 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 44 - loss: 0.068, f1: 0.976, precision: 0.968, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 44 - loss: 0.361, f1: 0.593, precision: 0.523, recall: 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 45 - loss: 0.066, f1: 0.976, precision: 0.969, recall: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 45 - loss: 0.358, f1: 0.606, precision: 0.565, recall: 0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 46 - loss: 0.066, f1: 0.976, precision: 0.969, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 46 - loss: 0.320, f1: 0.598, precision: 0.548, recall: 0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 47 - loss: 0.068, f1: 0.976, precision: 0.967, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 47 - loss: 0.348, f1: 0.584, precision: 0.517, recall: 0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 48 - loss: 0.067, f1: 0.975, precision: 0.968, recall: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 48 - loss: 0.375, f1: 0.610, precision: 0.557, recall: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 49 - loss: 0.064, f1: 0.978, precision: 0.971, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 49 - loss: 0.347, f1: 0.609, precision: 0.548, recall: 0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [02:04<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 50 - loss: 0.066, f1: 0.977, precision: 0.969, recall: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:13<00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval epoch 50 - loss: 0.344, f1: 0.586, precision: 0.502, recall: 0.704\n",
      "CPU times: total: 2h 1min 25s\n",
      "Wall time: 2h 13min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "SAVE_DIR = f\"logs-minilm-cl{MAX_LENGTH}-lingraph_{INCLUDE_GRAPH}\"\n",
    "\n",
    "train(\n",
    "    lora_model,\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    optimizer,  \n",
    "    loss_fn,\n",
    "    epochs=EPOCHS,\n",
    "    save_dir = SAVE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "best_lora_model = copy.deepcopy(lora_model)\n",
    "load_path = r\"C:\\keep_pc\\Skoltech-PC\\Courses\\Term 4\\DL for NLP\\Task 1\\work-2-from_repo\\text-graph\\all-MiniLM-L6-v2--lora-fixed_oversampling-pqlet-includegraphs.pth\"\n",
    "state_dict_loaded = torch.load(load_path)\n",
    "best_lora_model.model.load_state_dict(state_dict_loaded)\n",
    "# best_lora_model.load_state_dict(torch.load('logs-minilm-cl256-lingraph_True\\minilm--lora-fixed_oversampling-includegraphs-BEST.pth'))\n",
    "# best_lora_model.load_state_dict(torch.load('logs-minilm-cl256-lingraph_True\\minilm--lora-fixed_oversampling-includegraphs-LAST.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def make_submit_predictions(model, tokenizer, include_graph, filename='test_result_1.tsv'):\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', include_graph=include_graph)\n",
    "    preds = []\n",
    "    for idx, data in tqdm(enumerate(eval_ds)):\n",
    "        input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "        token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "        \n",
    "        logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "        pred = (logit.detach().cpu().numpy() > 0) * 1\n",
    "        preds.append(pred)\n",
    "\n",
    "    df = eval_ds.df\n",
    "    df['prediction'] = preds\n",
    "    df['prediction'] = df['prediction'].astype(int)\n",
    "    df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_submit_predictions_ranked(model, tokenizer, include_graph, filename='test_result_2.tsv', is_t5=False):\n",
    "    \"\"\"based of Vika's idea - select all candidate answers for questions, select one with max prob\"\"\"\n",
    "    model.eval()\n",
    "    eval_ds = TextGraphDataset(tokenizer, max_length=MAX_LENGTH,  train_path=train_path, test_path=test_path,\n",
    "                               split='eval', \n",
    "                               df_split=None,\n",
    "                               include_graph=include_graph)\n",
    "    eval_df = eval_ds.df\n",
    "    eval_df[\"correct\"] = False\n",
    "\n",
    "    for question in tqdm(eval_df['question'].unique()):\n",
    "        ids = eval_df.index[eval_df['question'] == question].tolist()\n",
    "        \n",
    "        logits = []\n",
    "        for idx in ids:\n",
    "            data = eval_ds[idx]\n",
    "            input_ids = data[\"input_ids\"].to(DEVICE).unsqueeze(0)\n",
    "            attention_mask = data[\"attention_mask\"].to(DEVICE).unsqueeze(0)\n",
    "            if is_t5:\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask,).squeeze()\n",
    "            else:\n",
    "                token_type_ids = data[\"token_type_ids\"].to(DEVICE).unsqueeze(0)\n",
    "                logit = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).squeeze()\n",
    "            \n",
    "            \n",
    "            logits.append(logit.detach().cpu().item())\n",
    "\n",
    "        right_ans_id = ids[np.argmax(logits)]\n",
    "        eval_df.loc[right_ans_id, 'correct'] = True\n",
    "\n",
    "    eval_df['prediction'] = eval_df['correct']\n",
    "    eval_df['prediction'] = eval_df['prediction'].astype(int)\n",
    "    eval_df[[\"sample_id\", \"prediction\"]].to_csv(filename, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.49it/s]\n"
     ]
    }
   ],
   "source": [
    "make_submit_predictions_ranked(\n",
    "    best_lora_model,\n",
    "    tokenizer,\n",
    "    include_graph=INCLUDE_GRAPH,\n",
    "    filename=f\"{SAVE_DIR}/submission_bestsavedprevious.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpttv-jup",
   "language": "python",
   "name": "cmpttv-jup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
